{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we will build a neural network of to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/arindamchoudhury/ml-projects/blob/main/MNIST_Handwritten_Digits.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "## YOUR CODE HERE ##\n",
    "# https://nextjournal.com/gkoehler/pytorch-mnist Normalize params \n",
    "transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "# Create training set and define training dataloader\n",
    "## YOUR CODE HERE ##\n",
    "training_dataset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(training_dataset, [50000, 10000])\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "## YOUR CODE HERE ##\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "show5(train_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base of the LeNet5 collected from https://github.com/rgkannan676/MNIST-Handwritten-Digit-Recognition/blob/main/OptmizerSelection.py\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.bn1 = nn.BatchNorm1d(120)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        self.bn2 = nn.BatchNorm1d(84)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc3.weight, nonlinearity='relu')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv1_bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.conv2_bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool2(out)\n",
    "\n",
    "        out = out.view(-1,16*5*5)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "net = LeNet5()\n",
    "net.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    _, yhat = torch.max(logits.data, dim=1)\n",
    "    equals = yhat == labels\n",
    "    return torch.mean(equals.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected from https://www.coursera.org/projects/pneumonia-classification-using-pytorch\n",
    "class ModelTrainer():\n",
    "    def __init__(self, criterion = None, optimizer = None):        \n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "  \n",
    "    def train_batch_loop(self, model, trainloader):        \n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        for images,labels in tqdm(trainloader):            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss = self.criterion(logits, labels)\n",
    "                        \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += accuracy(logits, labels)\n",
    "            \n",
    "        return train_loss / len(trainloader), train_acc / len(trainloader) \n",
    "\n",
    "    \n",
    "    def valid_batch_loop(self, model, validloader):        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for images,labels in tqdm(validloader):                \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "             \n",
    "            logits = model(images)\n",
    "            loss = self.criterion(logits, labels)\n",
    "              \n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(logits, labels)\n",
    "            \n",
    "        return valid_loss / len(validloader), valid_acc / len(validloader)\n",
    "            \n",
    "        \n",
    "    def fit(self, model, trainloader, validloader, epochs, filename):        \n",
    "        valid_min_loss = np.Inf\n",
    "        train_loss_history = list()\n",
    "        valid_loss_history = list()\n",
    "        \n",
    "        for i in range(epochs):            \n",
    "            model.train()\n",
    "            avg_train_loss, avg_train_acc = self.train_batch_loop(model, trainloader)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            model.eval()\n",
    "            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model, validloader)\n",
    "            valid_loss_history.append(avg_valid_loss)\n",
    "            \n",
    "            if avg_valid_loss < valid_min_loss:\n",
    "                print(f\"validation loss decreased {valid_min_loss} --> {avg_valid_loss}\")\n",
    "                torch.save(model.state_dict(), filename)\n",
    "                valid_min_loss = avg_valid_loss\n",
    "\n",
    "                \n",
    "            print(f\"Epoch : {i+1} Train Loss : {avg_train_loss:.6f} Train Acc : {avg_train_acc:.6f}\")\n",
    "            print(f\"Epoch : {i+1} Valid Loss : {avg_valid_loss:.6f} Valid Acc : {avg_valid_acc:.6f} Min Loss : {valid_min_loss:.6f}\")\n",
    "        \n",
    "        return train_loss_history, valid_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  optim.Adam(net.parameters(), lr=0.003, weight_decay=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = ModelTrainer(criterion, optimizer)\n",
    "train_loss_history, valid_loss_history = trainer.fit(model=net, trainloader=train_loader, validloader=valid_loader, epochs=20, filename=\"leNet.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss and validation loss/accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "plt.plot(valid_loss_history, label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = LeNet5()\n",
    "test_net.to(device)\n",
    "test_net.load_state_dict(torch.load('leNet.pt'))\n",
    "test_net.eval()\n",
    "\n",
    "avg_test_loss, avg_test_acc = trainer.valid_batch_loop(test_net, test_loader)\n",
    "\n",
    "\n",
    "print(\"Test Loss : {}\".format(avg_test_loss))\n",
    "print(\"Test Acc : {}\".format(avg_test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"LeNetFinal.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
